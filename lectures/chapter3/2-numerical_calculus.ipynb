{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p style=\"text-align: center;\"><font size=\"8\"><b>Numerical Calculus</b></font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In science and engineering (and lots of other disciplines), a common task is to evaluate derivatives or integrals. \n",
    "\n",
    "You probably already know how to take the derivative of a function, and how to compute (certain) integrals by hand (analytically). Often however, evaluating these quantities can be challenging or impossible analytically. Using a computer, we can come up with an approximation to these quantities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Derivatives\n",
    "\n",
    "In calculus you learnt how to take the derivative of a function. For example:\n",
    "\n",
    "- $ \\frac{\\text{d}}{\\text{d}x} x^2 = 2x$\n",
    "\n",
    "- $ \\frac{\\text{d}}{\\text{d}x} \\sin(x) = \\cos(x)$\n",
    "\n",
    "Using the chain rule and product rule, we can compute more complicated derivatives:\n",
    "$$ \\frac{\\text{d}}{\\text{d}x} \\sin(x^2\\cos(e^x)) = ?$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So what's the problem? Using the chain rule and product rule may be cumbersome, but it's possible. \n",
    "\n",
    "Well that's true. But what about a function like this:\n",
    "$$ f(x) = \\prod\\limits_{k=1}^{100} x^k\\left(\\sin\\left(k\\prod\\limits_{m=1}^k xe^{\\cos^{m}(x^2)}\\right)\\right).$$\n",
    "\n",
    "Would you want to take the derivative of that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It turns out that seeing functions like that isn't actually very common in most applications. Most functions you have to deal with can be differentiated by applying the chain rule once or twice. \n",
    "\n",
    "A more common task however, is to compute the derivative of function without being given $f(x)$. \n",
    "\n",
    "Consider a running app that keeps track of the runner's position at discrete time intervals. The data might look like:\n",
    "\n",
    "| time (s)| distance (m)|\n",
    "|-----------|------|\n",
    "|0 | 0 |\n",
    "|10 | 50|\n",
    "|20 | 100|\n",
    "|30 | 140|\n",
    "|40 | 180|\n",
    "\n",
    "How fast is the runner running at $t=30$? We know that velocity is the derivative of the position, i.e. $v(t) = \\text{d}/\\text{dt} (d(t))$. How can we compute this from the data provided by the app?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Another task where we are not given $f(x)$ but are interested in its derivative is where we are asked to solve an equation for $f(x)$ involving its derivative, for example:\n",
    "$$ \\frac{\\text{d}}{\\text{d}x} f(x) = x^3\\sin(x).$$\n",
    "\n",
    "This is called an *ordinary differential equation* (ODE). We'll cover techniques to solve ODEs in a few weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Finite Difference\n",
    " \n",
    "Remember from early calculus when you learnt the definition of the derivative. Given a function $y(x)$, the derivative $y'(x)$ is defined by the limit:\n",
    "\n",
    "$$ y'(x) = \\lim\\limits_{\\Delta x\\to 0} \\frac{y(x + \\Delta x) - y(x)}{\\Delta x} $$\n",
    "\n",
    "We can think of this as the limit of the slope of the secant line going through $f(x)$ and $f(x + \\Delta x)$.\n",
    "\n",
    "![derivative animation](https://github.com/lukasbystricky/ISC-3313/blob/master/lectures/chapter2/images/derivative.gif?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is the exact definition of a derivative. If we are willing to sacrifice some accuracy, we can *approximate* the derivative of a function by:\n",
    "$$ f'(x) \\approx \\frac{f(x + \\Delta x) - f(x)}{\\Delta x}.$$\n",
    "\n",
    "For large $\\Delta x$ this might be a bad approximation, but as $\\Delta x$ becomes closer to 0, the approximation becomes better. This is known as *finite difference*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can use this formula to answer a question from earlier. Given this time vs. distance data, how fast is the runner running at $t=30$?\n",
    "\n",
    "| time (s)| distance (m)|\n",
    "|-----------|------|\n",
    "|0 | 0 |\n",
    "|10 | 50|\n",
    "|20 | 100|\n",
    "|30 | 140|\n",
    "|40 | 180|\n",
    "\n",
    "In other words, if we call our distance function $d(t)$, what is $d'(30)$? \n",
    "\n",
    "From our finite difference formula:\n",
    "$$ d'(30) \\approx \\frac{d(30 + \\Delta t) - d(30)}{\\Delta t}.$$\n",
    "\n",
    "We know $d(30) = 140$. What is $\\Delta t$? \n",
    "\n",
    "From our table we can see that if we take $\\Delta t=10$, we can evaluate $d(30 + \\Delta t) = d(40) = 180$. \n",
    "\n",
    "Plugging this all in:\n",
    "$$ v(30) = d'(30) \\approx \\frac{180 - 140}{10} = 4 \\text{m/s}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There are different kinds of finite difference. The version on the last slide is known as *forward finite difference* because we are using the point $x$**+**$\\Delta x$ to approximate the derivative.\n",
    "\n",
    "We can also define a *backward finite difference*:\n",
    "$$ f'(x) \\approx \\frac{f(x) - f(x-\\Delta x)}{\\Delta x}.$$\n",
    "\n",
    "Or a *centered finite difference*:\n",
    "$$ f'(x) \\approx \\frac{f(x + \\Delta x) - f(x -\\Delta x)}{2\\Delta x}$$\n",
    "\n",
    "In fact there are many other finite difference schemes availiable, but we'll limit ourselves to these three."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now we have three finite difference schemes. Which one should you use?\n",
    "\n",
    "It turns out the centered finite diffence is the most accurate, so you should use this if you can. This might not always be possible. For example, given the data:\n",
    "\n",
    "| time (s)| distance (m)|\n",
    "|-----------|------|\n",
    "|0 | 0 |\n",
    "|10 | 50|\n",
    "|20 | 90|\n",
    "|30 | 140|\n",
    "|40 | 180|\n",
    "\n",
    "We can use centered finite difference to evaluate $v(30)$:\n",
    "$$ v(30) = d'(30) \\approx \\frac{180 - 90}{20} = 4.5 \\text{m/s}.$$\n",
    "Notice that this is different from what we got using forward finite difference. \n",
    "\n",
    "What is $v(0) = d'(0)$? To use centered finite difference you'd need to know $d(-\\Delta t)$, which is not known. So for this point we would have to use forward finite difference. Similarily at $t=40$, since we don't know $d(40+\\Delta t)$, we would have to use backward finite difference to evaluate $d'(40)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So how do we program this? Let's first create a NumPy array that represents the data.\n",
    "\n",
    "| time (s)| distance (m)|\n",
    "|-----------|------|\n",
    "|0 | 0 |\n",
    "|10 | 50|\n",
    "|20 | 90|\n",
    "|30 | 140|\n",
    "|40 | 180|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  10  20  30  40]\n",
      " [  0  50  90 140 180]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([[0,10,20,30,40],[0,50,90,140,180]])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can use this array to compute $v(0)$ using forward finite difference. The first row of `data` is the time, the second row is the distance. Let's extract this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = data[0] # first row of data\n",
    "d = data[1] # second row of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need:\n",
    "- d(0) : d[0]\n",
    "- d(10) : d[1]\n",
    "\n",
    "In addition, we'll need $\\Delta t$. We can find this from:\n",
    "\n",
    "$\\Delta t$ = t[1] - t[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "v0 = (d[1] - d[0])/(t[1] - t[0])\n",
    "print(v0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "\n",
    "Use  backward finite difference to compute the runner's velocity at $t=20$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Centered finite difference can be computed the same way. For example to compute the velocity at $t=10$ using centered finite difference we could call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5\n"
     ]
    }
   ],
   "source": [
    "v1 = (d[2] - d[0])/(t[2] - t[0])\n",
    "print(v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise \n",
    "\n",
    "Use centered finite difference to compute the runner's velocity at $t=20$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's put this all together. We'll use forward difference to compute $v(0)$, centered difference to compute $v(10)$, $v(20)$ and $v(30)$ and backward difference to compute $v(40)$. \n",
    "\n",
    "Of course we can compute these values all individually. If the app provided much more data however, maybe 10000 points, computing the velocity for each point would become very cumbersome. Instead, let's use NumPy arrays and slicing to our advantage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Since there's only ever two endpoints, we can compute those individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# left end, use forward difference\n",
    "v_start = (d[1] - d[0])/(t[1] - t[0])\n",
    "\n",
    "# right end, use backward difference\n",
    "# index -1 is last entry, index -2 is second to last\n",
    "v_end = (d[-1] - d[-2])/(t[-1] - t[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The non-endpoints, of which there can be an arbitrary number, will be computed using centered difference. We will use slicing. \n",
    "\n",
    "Recall that centered finite difference takes the form:\n",
    "$$ d'(t) \\approx \\frac{d(t+\\Delta t) - f(t - \\Delta t)}{\\Delta t}$$\n",
    "\n",
    "If we label each time-distance pair as $(t_i, d_i)$, then the derivative at each time $t_i$ can be written as:\n",
    "$$ d'(t_i) \\approx \\frac{d(t_{i+1}) - d(t_{i-1})}{t_{i+1} - t_{i-1}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can store $d(t_{i+1})$, $d(t_{i-1})$, $t_{i+1}$ and $t_{i-1}$ as NumPy arrays:\n",
    "\n",
    "$$ t_{i+1} = \\langle 20,30,40\\rangle$$\n",
    "$$ t_{i-1} = \\langle 0,10,20\\rangle$$\n",
    "$$ d(t_{i+1}) = \\langle 90, 140, 180\\rangle$$\n",
    "$$ d(t_{i-1}) = \\langle 0, 10, 20\\rangle$$\n",
    "\n",
    "In other words, the $i+1$ entries start at entry 2 (or 1 in Python indexing) and go on until the end. The $i-1$ entries start at entry 0 and go until 2 from the end (entry -2 in Python indexing). \n",
    "\n",
    "An implementation is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.   4.5  4.5  4.5  4. ]\n"
     ]
    }
   ],
   "source": [
    "# non-endpoints, use centered difference\n",
    "v = (d[2:]-d[:-2])/(t[2:]-t[:-2])\n",
    "\n",
    "# put everything together\n",
    "v = np.append(v_start, v)\n",
    "v = np.append(v, v_end)\n",
    "\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "Repeat this procedure to compute the velocity of a runner as a function of time having the following time vs. distance data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.            5.26315789   10.52631579   15.78947368   21.05263158\n",
      "    26.31578947   31.57894737   36.84210526   42.10526316   47.36842105\n",
      "    52.63157895   57.89473684   63.15789474   68.42105263   73.68421053\n",
      "    78.94736842   84.21052632   89.47368421   94.73684211  100.        ]\n",
      " [   0.           -8.52122368   -8.91903859   -0.81420188    8.06682555\n",
      "     9.25762867    1.62299723   -7.55886151   -9.5347456    -2.42101545\n",
      "     7.00070459    9.74854923    3.20295747   -6.3960611    -9.89761987\n",
      "    -3.96363099    5.74894603    9.98096763    4.69798492   -5.06365641]]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([np.linspace(0,100,20), 10*np.sin(np.linspace(0, 100, 20))])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Integration\n",
    "\n",
    "The reverse of differentiation is integration. In  many applications we need to integrate a function, i.e.\n",
    "\n",
    "$$\\int_0^{\\pi} \\sin(x)\\text{d}x$$\n",
    "\n",
    "This is easy enough. We know the antiderivative of $\\sin(x)$ is $-\\cos(x)$, so applying the fundamental theorem of calculus gives:\n",
    "$$ \\int_0^{\\pi} \\sin(x)\\text{d}x = -\\cos(\\pi) - (-\\cos(0)) = -(-1) + 1 = 2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What about the integral\n",
    "$ \\int_0^1 e^{x^2}\\text{d}x$ ? \n",
    "\n",
    "You may remember from calculus that $e^{x^2}$ does not have an antiderivative. Unlike differentiation, where finding analytic expressions can be tedious, but is almost always possible, finding an analytic expression for an integral is often not possible. \n",
    "\n",
    "Of course, just because we don't have an antiderivative doesn't mean we don't have an integral. Remember that the integral above is simply \"the area under the curve $y = e^{x^2}$ from $x=0$ to $x=1$\". This value still exists.\n",
    "\n",
    "![e^{x^2}](https://github.com/lukasbystricky/ISC-3313/blob/master/lectures/chapter2/images/plot.png?raw=true)\n",
    "\n",
    "So what can we do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When you first learnt about integrals you probably went over Riemann sums to evaluate $\\int_a^b f(x)\\text{d}x$. \n",
    "\n",
    "We begin by breaking up the interval of integration $[a,b]$ into intervals of length $h$. Then the value of the function at a point $x^*$ in each interval (typically either right endpoint, left endpoint or center) determines a rectangle of height $f(x^*)$ and width $h$. The integral of $f(x)$ over $[a,b]$ is then approximated by the total area of these rectangles. You'll recall that as $h\\to 0$, this approximation converges to the actual value of the integral. \n",
    "\n",
    "![left reimann sum](https://github.com/lukasbystricky/ISC-3313/blob/master/lectures/chapter2/images/left_sum.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Mathematically:\n",
    "\n",
    "1) we split the domain $[a,b]$ into $N$ equally spaced intervals of width $h$\n",
    "\n",
    "2) we take a point from each interval to form a set of points $\\{x_1, x_2, \\cdot x_N\\}$\n",
    "\n",
    "3) $\\int_a^b f(x)\\text{d}x \\approx h\\sum\\limits_{i=0}^N f(x_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the limit $h\\to 0$ this converges to the actual integral. Of course even if $h$ is not 0, it tells us something about the integral. As with finite differences, if we are willing to accept some error, we can take a non-zero $h$ and get an approximation to the integral. \n",
    "\n",
    "If $N$ is large enough (and consequently $h$ is small enough), this approximation might be quite good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Lets look at how we could compute this. As a specific example we'll look at an integral we already know how to compute, and see how accurate we can get. Specifically we'll look at $\\int_0^{\\pi} \\sin(x)\\text{d}x = 2$.\n",
    "\n",
    "The first thing we need to do is define the intervals. Say we want $N$ points, this means we'll have $N-1$ intervals and $h = \\pi/(N-1)$. NumPy provides a function `linspace` that returns an `array` of equally spaced numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.78539816  1.57079633  2.35619449  3.14159265]\n"
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "a = 0\n",
    "b = np.pi\n",
    "h = (b - a)/(N-1)\n",
    "x = np.linspace(a, b, N)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Lets do the left Reimann sum. This means that we need the left endpoint of each interval. In our case this will be the points $\\{0, \\pi/4, \\pi/2, 3\\pi/4\\}$, or all points except the last one. \n",
    "\n",
    "As we saw earlier with finite differences, arrays, like lists and strings support slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.78539816  1.57079633  2.35619449]\n"
     ]
    }
   ],
   "source": [
    "x = x[:-1]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We now need to plug these values into our function, sum the function values up and multiply by $h$. \n",
    "\n",
    "Note that instead of using `math.sin(x)`, we will use `np.sin(x)`. The reason for this is that the math module is completely unaware of NumPy arrays. If we tried to pass in an array to `math.sin(x)` we would get an error. On the other hand `np.sin(x)` works with arrays, and returns an array containing the values of sine at all the points in `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error =  0.103881102063\n"
     ]
    }
   ],
   "source": [
    "I = np.sum(np.sin(x))*h\n",
    "print(\"error = \", abs(I - 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This isn't bad, but it's still off by about 5%. What happens if instead of 5 points we use 100 points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error =  0.000167836106007\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "a = 0\n",
    "b = np.pi\n",
    "h = (b - a)/(N-1)\n",
    "x = np.linspace(a, b, N)\n",
    "x = x[:-1]\n",
    "I = np.sum(np.sin(x))*h\n",
    "print(\"error = \", abs(I - 2))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
